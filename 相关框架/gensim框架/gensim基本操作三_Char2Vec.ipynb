{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules & set up logging\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "\n",
    "import jieba.analyse\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_file_path = './datas/in_the_name_of_people.txt'\n",
    "word_file_path = './datas/cut_chars_of_in_the_name_of_people.txt'\n",
    "model_file_path1 = './datas/gensim_char2vec1.w2v'\n",
    "model_file_path2 = './datas/gensim_char2vec2.bin'\n",
    "model_file_path3 = './datas/gensim_char2vec3_{}.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "2023-09-15 22:25:57,557 : DEBUG : Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\HP\\AppData\\Local\\Temp\\jieba.cache\n",
      "2023-09-15 22:25:57,569 : DEBUG : Loading model from cache C:\\Users\\HP\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 2.334 seconds.\n",
      "2023-09-15 22:25:59,902 : DEBUG : Loading model cost 2.334 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "2023-09-15 22:25:59,905 : DEBUG : Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!!!\n"
     ]
    }
   ],
   "source": [
    "# 人民的名义 小说分词\n",
    "jieba.suggest_freq('沙瑞金',True)\n",
    "jieba.suggest_freq('田国富',True)\n",
    "jieba.suggest_freq('高育良',True)\n",
    "jieba.suggest_freq('侯亮平',True)\n",
    "jieba.suggest_freq('钟小艾', True)\n",
    "jieba.suggest_freq('陈岩石', True)\n",
    "jieba.suggest_freq('欧阳菁', True)\n",
    "jieba.suggest_freq('易学习', True)\n",
    "jieba.suggest_freq('王大路', True)\n",
    "jieba.suggest_freq('蔡成功', True)\n",
    "jieba.suggest_freq('孙连城', True)\n",
    "jieba.suggest_freq('季昌明', True)\n",
    "jieba.suggest_freq('丁义珍', True)\n",
    "jieba.suggest_freq('郑西坡', True)\n",
    "jieba.suggest_freq('赵东来', True)\n",
    "jieba.suggest_freq('高小琴', True)\n",
    "jieba.suggest_freq('赵瑞龙', True)\n",
    "jieba.suggest_freq('林华华', True)\n",
    "jieba.suggest_freq('陆亦可', True)\n",
    "jieba.suggest_freq('刘新建', True)\n",
    "jieba.suggest_freq('刘庆祝', True)\n",
    "jieba.suggest_freq('京州市', True)\n",
    "jieba.suggest_freq('副市长', True)\n",
    "jieba.suggest_freq('赵德汉',True)\n",
    "\n",
    "with open(word_file_path,'w', encoding='utf-8') as writer:\n",
    "    with open(sentence_file_path, 'r', encoding='utf-8') as reader:\n",
    "        # 加载所有数据\n",
    "        content = reader.read()\n",
    "        \n",
    "        # 分词 --> 以每个字作为独立的词\n",
    "        content = list(content)\n",
    "        \n",
    "        # 合并结果\n",
    "        result = ' '.join(content)\n",
    "        \n",
    "        # 结果输出\n",
    "        writer.write(result)\n",
    "print(\"Done!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、Gensim Word2Vec构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练方式一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 22:26:00,033 : INFO : collecting all words and their counts\n",
      "2023-09-15 22:26:00,037 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件路径:./datas/cut_chars_of_in_the_name_of_people.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 22:26:00,290 : INFO : collected 3269 word types from a corpus of 258973 raw words and 2311 sentences\n",
      "2023-09-15 22:26:00,291 : INFO : Creating a fresh vocabulary\n",
      "2023-09-15 22:26:00,330 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 3269 unique words (100.00% of original 3269, drops 0)', 'datetime': '2023-09-15T22:26:00.330931', 'gensim': '4.2.0', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18362-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-15 22:26:00,332 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 258973 word corpus (100.00% of original 258973, drops 0)', 'datetime': '2023-09-15T22:26:00.332765', 'gensim': '4.2.0', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18362-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-15 22:26:00,459 : INFO : deleting the raw counts dictionary of 3269 items\n",
      "2023-09-15 22:26:00,462 : INFO : sample=0.001 downsamples 69 most-common words\n",
      "2023-09-15 22:26:00,466 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 203917.56791381162 word corpus (78.7%% of prior 258973)', 'datetime': '2023-09-15T22:26:00.466609', 'gensim': '4.2.0', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18362-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-15 22:26:00,474 : INFO : constructing a huffman tree from 3269 words\n",
      "2023-09-15 22:26:00,860 : INFO : built huffman tree with maximum node depth 18\n",
      "2023-09-15 22:26:00,970 : INFO : estimated required memory for 3269 words and 100 dimensions: 6211100 bytes\n",
      "2023-09-15 22:26:00,973 : INFO : resetting layer weights\n",
      "2023-09-15 22:26:00,981 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-09-15T22:26:00.981938', 'gensim': '4.2.0', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18362-SP0', 'event': 'build_vocab'}\n",
      "2023-09-15 22:26:00,983 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 3269 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=3 shrink_windows=True', 'datetime': '2023-09-15T22:26:00.983933', 'gensim': '4.2.0', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18362-SP0', 'event': 'train'}\n",
      "2023-09-15 22:26:01,794 : INFO : EPOCH 0: training on 258973 raw words (204047 effective words) took 0.8s, 253662 effective words/s\n",
      "2023-09-15 22:26:02,682 : INFO : EPOCH 1: training on 258973 raw words (204010 effective words) took 0.9s, 231232 effective words/s\n",
      "2023-09-15 22:26:03,580 : INFO : EPOCH 2: training on 258973 raw words (204053 effective words) took 0.9s, 228542 effective words/s\n",
      "2023-09-15 22:26:04,363 : INFO : EPOCH 3: training on 258973 raw words (203687 effective words) took 0.8s, 261518 effective words/s\n",
      "2023-09-15 22:26:05,250 : INFO : EPOCH 4: training on 258973 raw words (203730 effective words) took 0.9s, 230925 effective words/s\n",
      "2023-09-15 22:26:05,252 : INFO : Word2Vec lifecycle event {'msg': 'training on 1294865 raw words (1019527 effective words) took 4.3s, 238945 effective words/s', 'datetime': '2023-09-15T22:26:05.252126', 'gensim': '4.2.0', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18362-SP0', 'event': 'train'}\n",
      "2023-09-15 22:26:05,254 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=3269, vector_size=100, alpha=0.025>', 'datetime': '2023-09-15T22:26:05.254121', 'gensim': '4.2.0', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18362-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# 每行数据加载\n",
    "print(f\"文件路径:{word_file_path}\")\n",
    "sentences = word2vec.LineSentence(word_file_path) \n",
    "\n",
    "# 训练Word2Vec模型\n",
    "\"\"\"\n",
    "classgensim.models.word2vec.Word2Vec(\n",
    "    sentences=None, corpus_file=None, \n",
    "    vector_size=100, alpha=0.025, window=5, min_count=5, max_vocab_size=None, \n",
    "    sample=0.001, seed=1, workers=3, min_alpha=0.0001, \n",
    "    sg=0, hs=0, negative=5, ns_exponent=0.75, cbow_mean=1, \n",
    "    hashfxn=<built-in function hash>, epochs=5, \n",
    "    null_word=0, trim_rule=None, sorted_vocab=1, \n",
    "    batch_words=10000, compute_loss=False, \n",
    "    callbacks=(), comment=None, max_final_vocab=None, shrink_windows=True)\n",
    "sg: 1(Skip-gram) 0(CBOW)\n",
    "hs: 1(hierarchical softmax) 0(negative)\n",
    "negative: 当hs为0的时候，给定负样本数目，给定为0表示不采用负采样\n",
    "\"\"\"\n",
    "model = word2vec.Word2Vec(sentences, hs = 1,min_count = 1,window = 3,vector_size = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练方式二"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 22:26:05,272 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=100, alpha=0.025>', 'datetime': '2023-09-15T22:26:05.272851', 'gensim': '4.2.0', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18362-SP0', 'event': 'created'}\n",
      "2023-09-15 22:26:05,286 : INFO : collecting all words and their counts\n",
      "2023-09-15 22:26:05,294 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-09-15 22:26:05,536 : INFO : collected 3269 word types from a corpus of 258973 raw words and 2311 sentences\n",
      "2023-09-15 22:26:05,539 : INFO : Creating a fresh vocabulary\n",
      "2023-09-15 22:26:05,588 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 3269 unique words (100.00% of original 3269, drops 0)', 'datetime': '2023-09-15T22:26:05.588623', 'gensim': '4.2.0', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18362-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-15 22:26:05,591 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 258973 word corpus (100.00% of original 258973, drops 0)', 'datetime': '2023-09-15T22:26:05.591616', 'gensim': '4.2.0', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18362-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-15 22:26:05,672 : INFO : deleting the raw counts dictionary of 3269 items\n",
      "2023-09-15 22:26:05,676 : INFO : sample=0.001 downsamples 69 most-common words\n",
      "2023-09-15 22:26:05,680 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 203917.56791381162 word corpus (78.7%% of prior 258973)', 'datetime': '2023-09-15T22:26:05.680566', 'gensim': '4.2.0', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18362-SP0', 'event': 'prepare_vocab'}\n",
      "2023-09-15 22:26:05,686 : INFO : constructing a huffman tree from 3269 words\n",
      "2023-09-15 22:26:06,041 : INFO : built huffman tree with maximum node depth 18\n",
      "2023-09-15 22:26:06,146 : INFO : estimated required memory for 3269 words and 100 dimensions: 6211100 bytes\n",
      "2023-09-15 22:26:06,147 : INFO : resetting layer weights\n",
      "2023-09-15 22:26:06,153 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-09-15T22:26:06.153358', 'gensim': '4.2.0', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18362-SP0', 'event': 'build_vocab'}\n",
      "2023-09-15 22:26:06,156 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 3269 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=9 shrink_windows=True', 'datetime': '2023-09-15T22:26:06.156350', 'gensim': '4.2.0', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18362-SP0', 'event': 'train'}\n",
      "2023-09-15 22:26:07,174 : INFO : EPOCH 0 - PROGRESS: at 97.27% examples, 193508 words/s, in_qsize 1, out_qsize 1\n",
      "2023-09-15 22:26:07,201 : INFO : EPOCH 0: training on 258973 raw words (203973 effective words) took 1.0s, 196248 effective words/s\n",
      "2023-09-15 22:26:08,215 : INFO : EPOCH 1 - PROGRESS: at 83.56% examples, 171625 words/s, in_qsize 5, out_qsize 0\n",
      "2023-09-15 22:26:08,310 : INFO : EPOCH 1: training on 258973 raw words (203809 effective words) took 1.1s, 186094 effective words/s\n",
      "2023-09-15 22:26:09,280 : INFO : EPOCH 2: training on 258973 raw words (203700 effective words) took 1.0s, 211249 effective words/s\n",
      "2023-09-15 22:26:10,316 : INFO : EPOCH 3 - PROGRESS: at 92.82% examples, 181315 words/s, in_qsize 3, out_qsize 0\n",
      "2023-09-15 22:26:10,359 : INFO : EPOCH 3: training on 258973 raw words (203761 effective words) took 1.1s, 189608 effective words/s\n",
      "2023-09-15 22:26:11,324 : INFO : EPOCH 4: training on 258973 raw words (203602 effective words) took 1.0s, 212250 effective words/s\n",
      "2023-09-15 22:26:11,327 : INFO : Word2Vec lifecycle event {'msg': 'training on 1294865 raw words (1018845 effective words) took 5.2s, 197104 effective words/s', 'datetime': '2023-09-15T22:26:11.327366', 'gensim': '4.2.0', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18362-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1018845, 1294865)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 每行数据加载\n",
    "sentences = word2vec.LineSentence(word_file_path) \n",
    "\n",
    "# 训练Word2Vec模型\n",
    "model = word2vec.Word2Vec(hs = 1,min_count = 1,window = 9,vector_size = 100)\n",
    "\n",
    "# 构建词典\n",
    "model.build_vocab(sentences)\n",
    "\n",
    "# 模型训练\n",
    "model.train(sentences, total_examples=model.corpus_count, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、Word2Vec应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 获取Word2Vec模型相关属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【词汇数目】: 3269\n",
      "【转换的稠密的特征向量维度数目,每个单词转换的向量维度大小】: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"【词汇数目】: {}\".format(len(model.wv.key_to_index)))\n",
    "print(\"【转换的稠密的特征向量维度数目,每个单词转换的向量维度大小】: {}\".format(model.wv.vector_size))\n",
    "# print(\"【单词到id的映射关系】: \\n{}\".format(model.wv.key_to_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 获取相似度最高的K个演员"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "龙 0.6806393265724182\n",
      "音 0.5905642509460449\n",
      "棺 0.5317568182945251\n",
      "讯 0.5231453776359558\n",
      "赞 0.4964260756969452\n"
     ]
    }
   ],
   "source": [
    "# 夹角余弦相似度\n",
    "req_count = 5\n",
    "for key in model.wv.similar_by_word('沙', topn =100):\n",
    "    req_count -= 1\n",
    "    print(key[0], key[1])\n",
    "    if req_count == 0:\n",
    "        break;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 获取单词之间的相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.1568283\n"
     ]
    }
   ],
   "source": [
    "# 夹角余弦相似度\n",
    "print(model.wv.similarity('沙', '瑞'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 获取单词的词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "[-0.1412568  -0.18312506  0.28488874 -0.19689868 -0.04151535 -0.12202216\n",
      " -0.39421114  0.57379025 -0.03881591 -0.47904474 -0.5288144  -0.45011202\n",
      "  1.0888281   0.6845412   0.36703792 -0.26092514 -0.63417363 -0.87472093\n",
      " -0.2707515  -0.47596595 -0.22023484  0.22903512 -0.39029452  0.12058085\n",
      "  0.21551585 -0.87997866  0.30429983 -0.51313174  0.1837985   0.49339062\n",
      " -0.36594316 -1.0341128   0.42795333  0.7066203  -0.44232622 -0.46763116\n",
      "  0.18078515  0.72454214  0.4951955   0.54927534  2.058531    0.17165852\n",
      "  0.07457943  0.7987704  -0.3157886  -0.41275406 -0.3614257   0.2369887\n",
      "  0.15158649 -0.3007517   0.399728    1.3008378   0.7315833  -0.5965188\n",
      " -0.727052    0.44002172 -0.04997028  1.3276641   0.7014737  -0.2800626\n",
      "  0.50441384  0.47367907  0.21706422  0.53943616 -0.60093004 -0.13698621\n",
      " -0.5334136   0.39392334  0.6514524  -0.9085511  -0.32391208 -0.5555952\n",
      " -0.11478419  0.8660509  -0.14987792 -0.3460935   0.92810845  0.3718172\n",
      " -0.10933036  0.1174156   0.5322972  -0.5126592  -0.08869728 -0.37256142\n",
      " -1.2554246   0.23546332 -0.33978468 -1.0488648   1.2665792  -0.6914376\n",
      " -0.32927498  0.12056353  0.04947041  1.0126878  -0.5169857  -0.49434552\n",
      " -0.18091102  1.7501994  -0.4595358  -0.91257066]\n"
     ]
    }
   ],
   "source": [
    "v1 = model.wv.get_vector(\"提\")\n",
    "print(v1.shape)\n",
    "print(v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.1412568 , -0.18312506,  0.28488874, -0.19689868, -0.04151535,\n",
       "       -0.12202216, -0.39421114,  0.57379025, -0.03881591, -0.47904474,\n",
       "       -0.5288144 , -0.45011202,  1.0888281 ,  0.6845412 ,  0.36703792,\n",
       "       -0.26092514, -0.63417363, -0.87472093, -0.2707515 , -0.47596595,\n",
       "       -0.22023484,  0.22903512, -0.39029452,  0.12058085,  0.21551585,\n",
       "       -0.87997866,  0.30429983, -0.51313174,  0.1837985 ,  0.49339062,\n",
       "       -0.36594316, -1.0341128 ,  0.42795333,  0.7066203 , -0.44232622,\n",
       "       -0.46763116,  0.18078515,  0.72454214,  0.4951955 ,  0.54927534,\n",
       "        2.058531  ,  0.17165852,  0.07457943,  0.7987704 , -0.3157886 ,\n",
       "       -0.41275406, -0.3614257 ,  0.2369887 ,  0.15158649, -0.3007517 ,\n",
       "        0.399728  ,  1.3008378 ,  0.7315833 , -0.5965188 , -0.727052  ,\n",
       "        0.44002172, -0.04997028,  1.3276641 ,  0.7014737 , -0.2800626 ,\n",
       "        0.50441384,  0.47367907,  0.21706422,  0.53943616, -0.60093004,\n",
       "       -0.13698621, -0.5334136 ,  0.39392334,  0.6514524 , -0.9085511 ,\n",
       "       -0.32391208, -0.5555952 , -0.11478419,  0.8660509 , -0.14987792,\n",
       "       -0.3460935 ,  0.92810845,  0.3718172 , -0.10933036,  0.1174156 ,\n",
       "        0.5322972 , -0.5126592 , -0.08869728, -0.37256142, -1.2554246 ,\n",
       "        0.23546332, -0.33978468, -1.0488648 ,  1.2665792 , -0.6914376 ,\n",
       "       -0.32927498,  0.12056353,  0.04947041,  1.0126878 , -0.5169857 ,\n",
       "       -0.49434552, -0.18091102,  1.7501994 , -0.4595358 , -0.91257066],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['提']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 异常：不存在\"小明\"这个单词\n",
    "# model.wv.get_vector(\"小明\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【向量】:\n",
      "[-1.6461818  -1.0586804  -0.05233782  1.0272888   0.7208985   0.6484954\n",
      "  2.0570333   0.23740542  1.7734475  -0.4766108   2.0938504   3.5287266\n",
      " -0.6909583  -1.6923838  -2.118905   -1.47622     2.1244147   0.24693976\n",
      "  0.3159762  -1.0810101   1.6064044  -1.7139945   0.623651   -0.60801345\n",
      "  1.9721653   0.5068213   1.3088527  -1.939875   -3.0105808   0.6512234\n",
      " -0.0119812   2.3553255  -1.4937325  -1.4910252  -0.54609555  0.08085161\n",
      " -1.518993   -3.2818222  -2.1248455   2.0163708  -1.8022631   0.42989305\n",
      "  2.5546057   1.7766382   4.0128226  -2.3182504  -0.7139472  -1.8510693\n",
      "  0.43365258 -0.71715367  1.9800317  -0.42742136  0.18735449  0.4497837\n",
      " -1.4427707  -2.838277    1.9472058   0.33534107 -1.0588503  -1.1663908\n",
      " -0.16970505 -0.74356574 -0.05802837 -3.4141722  -2.341562    0.51540446\n",
      " -0.22367801  1.1214468   0.38174674 -1.8347814  -0.8771254   0.4472925\n",
      " -1.5586258  -0.7575157   0.42089006 -0.0642156  -1.079893   -1.1801511\n",
      " -2.0549808   0.04978392 -0.42684153  1.0748101   0.6243277  -0.7938578\n",
      "  2.0779803   1.4519596   0.20229442 -2.074897   -1.9616404   0.78110814\n",
      "  2.2631526   0.4942024  -0.35651857  1.6159362   1.2671707   1.8151059\n",
      "  0.5088112  -1.3264598  -0.5196013  -1.1588292 ]\n"
     ]
    }
   ],
   "source": [
    "# 首先判断是否存在单词，如果存在，就返回，否则单词直接过滤\n",
    "word = \"明\"\n",
    "# word = \"康\"\n",
    "if word in model.wv:\n",
    "    print(\"【向量】:\\n{}\".format(model.wv[word]))\n",
    "else:\n",
    "    print(\"【单词不存在】!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、模型持久化&模型恢复加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方式一：\n",
    "直接使用save API进行模型持久化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 持久化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 22:26:11,682 : INFO : Word2Vec lifecycle event {'fname_or_handle': './datas/gensim_char2vec1.w2v', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-09-15T22:26:11.682231', 'gensim': '4.2.0', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18362-SP0', 'event': 'saving'}\n",
      "2023-09-15 22:26:11,684 : INFO : not storing attribute cum_table\n",
      "2023-09-15 22:26:11,758 : INFO : saved ./datas/gensim_char2vec1.w2v\n"
     ]
    }
   ],
   "source": [
    "model.save(model_file_path1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 22:26:11,773 : INFO : loading Word2Vec object from ./datas/gensim_char2vec1.w2v\n",
      "2023-09-15 22:26:11,805 : INFO : loading wv recursively from ./datas/gensim_char2vec1.w2v.wv.* with mmap=None\n",
      "2023-09-15 22:26:11,808 : INFO : setting ignored attribute cum_table to None\n",
      "2023-09-15 22:26:11,882 : INFO : Word2Vec lifecycle event {'fname': './datas/gensim_char2vec1.w2v', 'datetime': '2023-09-15T22:26:11.882003', 'gensim': '4.2.0', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18362-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=3269, vector_size=100, alpha=0.025>\n",
      "(100,)\n",
      "[-0.1412568  -0.18312506  0.28488874 -0.19689868 -0.04151535 -0.12202216\n",
      " -0.39421114  0.57379025 -0.03881591 -0.47904474 -0.5288144  -0.45011202\n",
      "  1.0888281   0.6845412   0.36703792 -0.26092514 -0.63417363 -0.87472093\n",
      " -0.2707515  -0.47596595 -0.22023484  0.22903512 -0.39029452  0.12058085\n",
      "  0.21551585 -0.87997866  0.30429983 -0.51313174  0.1837985   0.49339062\n",
      " -0.36594316 -1.0341128   0.42795333  0.7066203  -0.44232622 -0.46763116\n",
      "  0.18078515  0.72454214  0.4951955   0.54927534  2.058531    0.17165852\n",
      "  0.07457943  0.7987704  -0.3157886  -0.41275406 -0.3614257   0.2369887\n",
      "  0.15158649 -0.3007517   0.399728    1.3008378   0.7315833  -0.5965188\n",
      " -0.727052    0.44002172 -0.04997028  1.3276641   0.7014737  -0.2800626\n",
      "  0.50441384  0.47367907  0.21706422  0.53943616 -0.60093004 -0.13698621\n",
      " -0.5334136   0.39392334  0.6514524  -0.9085511  -0.32391208 -0.5555952\n",
      " -0.11478419  0.8660509  -0.14987792 -0.3460935   0.92810845  0.3718172\n",
      " -0.10933036  0.1174156   0.5322972  -0.5126592  -0.08869728 -0.37256142\n",
      " -1.2554246   0.23546332 -0.33978468 -1.0488648   1.2665792  -0.6914376\n",
      " -0.32927498  0.12056353  0.04947041  1.0126878  -0.5169857  -0.49434552\n",
      " -0.18091102  1.7501994  -0.4595358  -0.91257066]\n"
     ]
    }
   ],
   "source": [
    "# 直接基于路径加载\n",
    "model2 = word2vec.Word2Vec.load(model_file_path1)\n",
    "print(model2)\n",
    "\n",
    "v1 = model2.wv.get_vector(\"提\")\n",
    "print(v1.shape)\n",
    "print(v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方式二：\n",
    "保存为二进制词向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 持久化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 22:26:11,913 : INFO : storing 3269x100 projection weights into ./datas/gensim_char2vec2.bin\n"
     ]
    }
   ],
   "source": [
    "model.wv.save_word2vec_format(model_file_path2,binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 22:26:11,986 : INFO : loading projection weights from ./datas/gensim_char2vec2.bin\n",
      "2023-09-15 22:26:12,102 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (3269, 100) matrix of type float32 from ./datas/gensim_char2vec2.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2023-09-15T22:26:12.102288', 'gensim': '4.2.0', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18362-SP0', 'event': 'load_word2vec_format'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyedVectors<vector_size=100, 3269 keys>\n",
      "(100,)\n",
      "[-0.1412568  -0.18312506  0.28488874 -0.19689868 -0.04151535 -0.12202216\n",
      " -0.39421114  0.57379025 -0.03881591 -0.47904474 -0.5288144  -0.45011202\n",
      "  1.0888281   0.6845412   0.36703792 -0.26092514 -0.63417363 -0.87472093\n",
      " -0.2707515  -0.47596595 -0.22023484  0.22903512 -0.39029452  0.12058085\n",
      "  0.21551585 -0.87997866  0.30429983 -0.51313174  0.1837985   0.49339062\n",
      " -0.36594316 -1.0341128   0.42795333  0.7066203  -0.44232622 -0.46763116\n",
      "  0.18078515  0.72454214  0.4951955   0.54927534  2.058531    0.17165852\n",
      "  0.07457943  0.7987704  -0.3157886  -0.41275406 -0.3614257   0.2369887\n",
      "  0.15158649 -0.3007517   0.399728    1.3008378   0.7315833  -0.5965188\n",
      " -0.727052    0.44002172 -0.04997028  1.3276641   0.7014737  -0.2800626\n",
      "  0.50441384  0.47367907  0.21706422  0.53943616 -0.60093004 -0.13698621\n",
      " -0.5334136   0.39392334  0.6514524  -0.9085511  -0.32391208 -0.5555952\n",
      " -0.11478419  0.8660509  -0.14987792 -0.3460935   0.92810845  0.3718172\n",
      " -0.10933036  0.1174156   0.5322972  -0.5126592  -0.08869728 -0.37256142\n",
      " -1.2554246   0.23546332 -0.33978468 -1.0488648   1.2665792  -0.6914376\n",
      " -0.32927498  0.12056353  0.04947041  1.0126878  -0.5169857  -0.49434552\n",
      " -0.18091102  1.7501994  -0.4595358  -0.91257066]\n"
     ]
    }
   ],
   "source": [
    "# 加载模型\n",
    "model2 = gensim.models.KeyedVectors.load_word2vec_format(model_file_path2,binary=True)\n",
    "print(model2)\n",
    "\n",
    "# 应用模型\n",
    "v1 = model2.get_vector(\"提\")\n",
    "print(v1.shape)\n",
    "print(v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 22:26:12,130 : INFO : loading projection weights from ./datas/vectors.bin\n",
      "2023-09-15 22:26:12,391 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (7942, 128) matrix of type float32 from ./datas/vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2023-09-15T22:26:12.391249', 'gensim': '4.2.0', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18362-SP0', 'event': 'load_word2vec_format'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyedVectors<vector_size=128, 7942 keys>\n",
      "(128,)\n",
      "[ 3.50566626e-01 -1.04986653e-01 -7.67363831e-02  1.02968253e-01\n",
      "  1.18330494e-01  5.92405088e-02  1.43829891e-02 -2.13755772e-01\n",
      "  3.01811416e-02  6.38461784e-02  9.29202810e-02 -9.80767310e-02\n",
      "  3.37989390e-01  1.62496209e-01 -1.00853711e-01  1.86467111e-01\n",
      "  1.23709984e-01  4.02765274e-02  1.66892633e-01 -1.33713201e-01\n",
      "  1.33725271e-01 -7.69479200e-02 -4.04792249e-01  1.34307100e-02\n",
      " -4.08627130e-02  1.60763144e-01 -2.02138210e-03 -2.05629498e-01\n",
      "  1.40110895e-01  1.38469696e-01  5.83793372e-02 -6.10959306e-02\n",
      "  2.09262501e-02  2.13176370e-01 -6.33254573e-02 -1.41293630e-01\n",
      "  8.06461945e-02  8.95849839e-02  8.80930126e-02 -9.46233943e-02\n",
      "  5.21726757e-02 -2.96247043e-02 -4.45053317e-02 -1.41549101e-02\n",
      " -1.64876487e-02  5.51286805e-03 -1.92858249e-01  1.42684672e-03\n",
      "  6.35003224e-02 -1.57157220e-02 -1.80648953e-01  1.67108551e-01\n",
      " -9.37882364e-02 -4.28168513e-02  4.31317948e-02  2.22156458e-02\n",
      " -2.61552483e-01 -2.04422385e-01 -1.23091996e-01  1.93861574e-02\n",
      "  1.46302849e-01  1.04037240e-01  1.23683989e-01  2.73934305e-02\n",
      "  1.92973882e-01  1.29787728e-01 -7.16170445e-02 -9.03484523e-02\n",
      " -2.32694391e-02  3.65361432e-03  1.15270486e-04 -2.14250758e-01\n",
      " -1.67434454e-01 -1.03420317e-01 -1.08205602e-01 -1.15225635e-01\n",
      "  9.30869207e-02 -3.24961841e-01 -8.96080807e-02  1.97890818e-01\n",
      " -1.02905326e-01  4.69629802e-02 -5.47558904e-01  1.09472692e-01\n",
      " -4.85083498e-02  4.09617126e-01 -4.29356575e-01  3.32381725e-01\n",
      "  1.69054210e-01  2.37728402e-01  2.31278166e-01 -3.59580368e-02\n",
      " -2.64627844e-01 -5.88537566e-02  1.91160694e-01  2.14405134e-01\n",
      " -6.86848024e-03 -6.25446215e-02  1.47033967e-02 -9.61678103e-02\n",
      " -1.10831551e-01  1.23344213e-01  7.87603203e-03  3.74681950e-02\n",
      " -4.81853485e-02 -8.42507035e-02 -2.31700063e-01 -2.77504884e-03\n",
      "  3.02709956e-02  1.85428590e-01 -6.45382628e-02 -9.52085778e-02\n",
      "  3.76226418e-02 -1.74595505e-01 -1.86821469e-03  2.73377329e-01\n",
      " -2.90656090e-01 -1.65097162e-01  1.26972899e-01  6.24788627e-02\n",
      " -1.76095635e-01 -1.18283860e-01  5.66130355e-02  8.49238038e-03\n",
      "  1.39976144e-01 -1.29547715e-01  1.40980124e-01 -1.26483599e-02]\n"
     ]
    }
   ],
   "source": [
    "# 加载模型\n",
    "model2 = gensim.models.KeyedVectors.load_word2vec_format('./datas/vectors.bin',\n",
    "                                                         binary=True)\n",
    "print(model2)\n",
    "\n",
    "# 应用模型\n",
    "v1 = model2.get_vector(\"酒\")\n",
    "print(v1.shape)\n",
    "print(v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 方式三：\n",
    "直接使用NumPy API保存词向量信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 持久化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3269, 100) (3269, 100) (3269, 2)\n"
     ]
    }
   ],
   "source": [
    "# 获取词向量\n",
    "norm_word_embeddings = model.wv.get_normed_vectors()\n",
    "word_embeddings = model.wv.vectors\n",
    "# 获取词典(词典到idx的映射)\n",
    "vocab_2_index = list(map(lambda k: (k, model.wv.key_to_index[k]), model.wv.key_to_index))\n",
    "print(np.shape(norm_word_embeddings), np.shape(word_embeddings), np.shape(vocab_2_index))\n",
    "# 数据保存\n",
    "np.save(model_file_path3.format(\"norm_embedding\"), norm_word_embeddings)\n",
    "np.save(model_file_path3.format(\"embedding\"), word_embeddings)\n",
    "np.save(model_file_path3.format(\"vocab_2_index\"), vocab_2_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "[-0.1412568  -0.18312506  0.28488874 -0.19689868 -0.04151535 -0.12202216\n",
      " -0.39421114  0.57379025 -0.03881591 -0.47904474 -0.5288144  -0.45011202\n",
      "  1.0888281   0.6845412   0.36703792 -0.26092514 -0.63417363 -0.87472093\n",
      " -0.2707515  -0.47596595 -0.22023484  0.22903512 -0.39029452  0.12058085\n",
      "  0.21551585 -0.87997866  0.30429983 -0.51313174  0.1837985   0.49339062\n",
      " -0.36594316 -1.0341128   0.42795333  0.7066203  -0.44232622 -0.46763116\n",
      "  0.18078515  0.72454214  0.4951955   0.54927534  2.058531    0.17165852\n",
      "  0.07457943  0.7987704  -0.3157886  -0.41275406 -0.3614257   0.2369887\n",
      "  0.15158649 -0.3007517   0.399728    1.3008378   0.7315833  -0.5965188\n",
      " -0.727052    0.44002172 -0.04997028  1.3276641   0.7014737  -0.2800626\n",
      "  0.50441384  0.47367907  0.21706422  0.53943616 -0.60093004 -0.13698621\n",
      " -0.5334136   0.39392334  0.6514524  -0.9085511  -0.32391208 -0.5555952\n",
      " -0.11478419  0.8660509  -0.14987792 -0.3460935   0.92810845  0.3718172\n",
      " -0.10933036  0.1174156   0.5322972  -0.5126592  -0.08869728 -0.37256142\n",
      " -1.2554246   0.23546332 -0.33978468 -1.0488648   1.2665792  -0.6914376\n",
      " -0.32927498  0.12056353  0.04947041  1.0126878  -0.5169857  -0.49434552\n",
      " -0.18091102  1.7501994  -0.4595358  -0.91257066]\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "norm_word_embeddings = np.load(model_file_path3.format(\"norm_embedding\"))\n",
    "word_embeddings = np.load(model_file_path3.format(\"embedding\"))\n",
    "vocab_2_index = np.load(model_file_path3.format(\"vocab_2_index\"))\n",
    "\n",
    "# 字典转换\n",
    "vocab_2_index = dict(map(lambda t:(t[0], int(t[1])), vocab_2_index))\n",
    "\n",
    "# 获取数据\n",
    "word = \"提\"\n",
    "index = vocab_2_index[word]\n",
    "v1 = word_embeddings[index]\n",
    "print(v1.shape)\n",
    "print(v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
